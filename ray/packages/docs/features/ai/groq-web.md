# Groq Web <Badge type="tip" text="^0.4.0-beta.0" /> <Badge type="danger" text="Deprecated" />

Raycast Unblock offers Groq Web AI support. You can use Groq's models for free via their Web API.

::: warning
Unfortunately, the cost of bypassing Cloudflare protection on the NodeJS platform is unacceptable in this project. **Therefore, we are unable to provide support for Groq Web AI.**
:::

---

::: danger
We found *Cloudflare protection*, which caused our program to fail to interact with `api.groq.com` normally. You can go to [wibus-wee/raycast-unblock#72](https://github.com/wibus-wee/raycast-unblock/issues/72) for more details.

~~We will try to solve this problem as soon as possible. _You can't use this feature until we fix it._~~
:::

::: warning
~~This is an inverted API. Please use with caution.~~

The following content is no longer maintained and is for reference only.
:::

## Usage

1. Open https://groq.com/ and log in. Open the Network tab in the console. Refresh the page.

2. Locate the `https://web.stytch.com/sdk/v1/sessions/authenticate` request in the Network tab. Look for the `Authorization` header in the request.

3. Copy the value of the `Authorization` header, which will be in the format `Basic xxx`.

4. In your configuration file, set `refreshToken` in `[AI.Groq]` to the copied value (a placeholder value is already provided in the example configuration).

## Configuration

The configuration for this feature includes the following parameters:

-  `refresh_token`: This parameter refers to the value of the `Authorization` header. It is used to authenticate and authorize the user's access to the system.
-  `temperature`: This parameter determines the variability and creativity of the output generated by the system. A higher temperature value will result in more random and diverse responses, while a lower value will produce more focused and deterministic output.
-  `max_tokens`: This parameter specifies the maximum number of tokens that the output should contain. Tokens can be thought of as individual units of text, such as words or characters. Setting a higher value for `max_tokens` will result in longer output, while a lower value will generate shorter responses.
- `default`: The default model to use. <Badge type="info" text="Optional" /> <Badge type="warning" text="^v0.5.0-beta.2" />

### Example

```toml
[AI.Groq]
refresh_token = '<your refresh token>'
# temperature = 0.5
# max_tokens = 100
```
